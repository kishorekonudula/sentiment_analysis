{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kishore/.local/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the classifier to classify negative and positive documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package subjectivity to\n",
      "[nltk_data]     /home/kishore/nltk_data...\n",
      "[nltk_data]   Package subjectivity is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kishore/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/kishore/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kishore/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import subjectivity\n",
    "nltk.download('subjectivity')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')]\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj_docs, test_subj_docs = train_test_split(subj_docs, test_size=.2)\n",
    "train_obj_docs, test_obj_docs = train_test_split(obj_docs, test_size=.2)\n",
    "training_docs = train_subj_docs + train_obj_docs\n",
    "testing_docs = test_subj_docs + test_obj_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentiment_analyzer.all_words([mark_negation(doc) for doc in training_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_feats = sentiment_analyzer.unigram_word_feats(all_words_neg, min_freq=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = sentiment_analyzer.apply_features(training_docs)\n",
    "test_set = sentiment_analyzer.apply_features(testing_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentiment_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.9235\n",
      "F-measure [obj]: 0.9214175654853622\n",
      "F-measure [subj]: 0.9254749147588895\n",
      "Precision [obj]: 0.9472016895459345\n",
      "Precision [subj]: 0.9021842355175689\n",
      "Recall [obj]: 0.897\n",
      "Recall [subj]: 0.95\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(sentiment_analyzer.evaluate(test_set).items()):\n",
    "...     print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag new documents and get sentiment intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"The service at MCD was surprisingly pleasant. Would recommend.\",\n",
    "             \"The employee was rude and manager didn't help\",\n",
    "             \"I worked here for 3 years and my manager never helped me\",\n",
    "             \"Just started here and impressed with the management team\",\n",
    "             \"Most automated sentiment analysis tools are shit\",\n",
    "             \"VADER sentiment analisys is the shit.\",\n",
    "             \"VADER is smart, handsome, and funny.\",\n",
    "             \"Poor direction\"]\n",
    "paragraph = \"\"\"Very bad exprnce\n",
    "               here at the restaurant\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_list = tokenize.sent_tokenize(paragraph)\n",
    "sentences.extend(lines_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The service at MCD was surprisingly pleasant. Would recommend.\n",
      "Positive\n",
      "compound : 0.7906, neg : 0.0, neu : 0.429, pos : 0.571, \n",
      "\n",
      "The employee was rude and manager didn't help\n",
      "Negative\n",
      "compound : -0.6437, neg : 0.467, neu : 0.533, pos : 0.0, \n",
      "\n",
      "I worked here for 3 years and my manager never helped me\n",
      "Neutral\n",
      "compound : 0.0, neg : 0.0, neu : 1.0, pos : 0.0, \n",
      "\n",
      "Just started here and impressed with the management team\n",
      "Positive\n",
      "compound : 0.4767, neg : 0.0, neu : 0.721, pos : 0.279, \n",
      "\n",
      "Most automated sentiment analysis tools are shit\n",
      "Negative\n",
      "compound : -0.5574, neg : 0.375, neu : 0.625, pos : 0.0, \n",
      "\n",
      "VADER sentiment analisys is the shit.\n",
      "Positive\n",
      "compound : 0.6124, neg : 0.0, neu : 0.556, pos : 0.444, \n",
      "\n",
      "VADER is smart, handsome, and funny.\n",
      "Positive\n",
      "compound : 0.8316, neg : 0.0, neu : 0.254, pos : 0.746, \n",
      "\n",
      "Poor direction\n",
      "Negative\n",
      "compound : -0.4767, neg : 0.756, neu : 0.244, pos : 0.0, \n",
      "\n",
      "Very bad exprnce\n",
      "               here at the restaurant\n",
      "Negative\n",
      "compound : -0.5849, neg : 0.387, neu : 0.613, pos : 0.0, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "for s in sentences:\n",
    "    print(s)\n",
    "    ss = sid.polarity_scores(s)\n",
    "    if ss['compound'] > 0:\n",
    "        senti = 'Positive'\n",
    "    elif ss['compound'] < 0:\n",
    "        senti = 'Negative'\n",
    "    else:\n",
    "        senti = 'Neutral'\n",
    "    print(senti)\n",
    "    for k in sorted(ss):\n",
    "        print(\"{0} : {1}, \".format(k, ss[k]), end='')\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
